{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXe6XAtCPdFM"
      },
      "source": [
        "# Real-time Data for LLMs\n",
        "This notebook demonstrates how to retrieve **real-time features** from TurboML and use them in **LLM prompts** for more **contextual** and **personalized** responses in real time.\n",
        "\n",
        "### Why Feature Platforms for LLMs?\n",
        "- **Real-time personalization**: Many LLM tasks benefit from fresh data (e.g., user’s recent transactions, recent chat sentiment) to personalize outputs.\n",
        "- **Low-latency data access**: Feature platforms are built for **real-time** lookups, enabling you to insert up-to-date stats at inference time.\n",
        "- **Consistency**: Feature platforms unify offline and online features, ensuring the same definitions are used for analytics/batch and real-time inference.\n",
        "\n",
        "When combined with LLMs, feature platforms enable a new paradigm of AI applications that can\n",
        "reason about current data while leveraging the powerful capabilities of language models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGTDXiy-PdFN"
      },
      "source": [
        "Set up the environment and install TurboML's SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-O9XsM3PdFN",
        "outputId": "a6e1ae34-509a-4255-804e-601727e913f4"
      },
      "outputs": [],
      "source": [
        "!pip install turboml-installer \n",
        "import turboml_installer ; turboml_installer.install_on_colab()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The kernel should now be restarted with TurboML's SDK installed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF7tkNhZPdFO"
      },
      "source": [
        "Login to your TurboML instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcr335pUVlpW"
      },
      "source": [
        "## 1. Install and Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WoDMmaFQPdFO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import turboml as tb\n",
        "\n",
        "#Initialize the TurboML platform\n",
        "tb.init(backend_url=BACKEND_URL, api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKu0p_tpVfHG"
      },
      "source": [
        "## 2. Initialize Feature Platform & Load Data\n",
        "We’ll initialize a connection to our **TurboML** feature platform, then upload a transactions dataset.\n",
        "\n",
        "\n",
        "We'll use TurboML’s **push-based ingestion** approach by uploading the pandas DataFrame via **`tb.OnlineDataset`**.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzeLWP9-PsZ1",
        "outputId": "78d5b64e-f7b8-4527-847f-9eceb6689aca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:turboml.common.dataloader:Uploading 201406 rows to dataset transactions_prompt\n",
            "Progress: 100%|██████████| 201k/201k [00:05<00:00, 37.9krows/s]\n",
            "INFO:turboml.common.dataloader:Upload complete. Waiting for server to process messages.\n"
          ]
        }
      ],
      "source": [
        "# Load and prepare transaction data\n",
        "try:\n",
        "    transactions_df = tb.datasets.FraudDetectionDatasetFeatures().df\n",
        "    transactions = tb.OnlineDataset.from_pd(\n",
        "        id=\"transactions_prompt\",\n",
        "        key_field=\"transactionID\",\n",
        "        df=transactions_df,\n",
        "        load_if_exists=True,\n",
        "    )\n",
        "except:\n",
        "    transactions = tb.OnlineDataset.from_pd(id=\"transactions_prompt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mg52FeIXZ2R"
      },
      "source": [
        "## 3. Feature Engineering\n",
        "Feature stores are invaluable because they can create **aggregated** or **transformed** features on the fly, then materialize them for real-time serving.\n",
        "\n",
        "Real-time features can be used to trigger or supplement an LLM-based pipeline (e.g., if user sentiment is dropping, take action, if transaction volume is unusually high, investigate fraud, etc.).\n",
        "\n",
        "### 3.1 Register Timestamp\n",
        "First, we register our timestamp column so we can perform time-based aggregations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZDz8ZZZTjy-S"
      },
      "outputs": [],
      "source": [
        "transactions.feature_engineering.register_timestamp(\n",
        "    column_name=\"timestamp\",\n",
        "    format_type=\"epoch_seconds\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yjd2D4rj1y-"
      },
      "source": [
        "### 3.2 Create Multiple Aggregations\n",
        "We’ll create the following **time-windowed** features:\n",
        "1. `my_sum_feat_24h`: Sum of transaction amounts in the last 24 hours (per account).\n",
        "2. `my_avg_feat_48h`: Average transaction amount in the last 48 hours (per account).\n",
        "3. `my_count_feat_7d`: Number of transactions in the last 7 days (per account).\n",
        "4. `my_max_feat_7d`: Maximum transaction in the last 7 days (per account).\n",
        "\n",
        "After creating them, we’ll **materialize** them so they’re available in the online store for real-time reads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pM0ZBePqPzQK"
      },
      "outputs": [],
      "source": [
        "# 1) Sum of transactionAmount over 24h\n",
        "transactions.feature_engineering.create_aggregate_features(\n",
        "    column_to_operate=\"transactionAmount\",\n",
        "    column_to_group=\"accountID\",\n",
        "    operation=\"SUM\",\n",
        "    new_feature_name=\"my_sum_feat_24h\",\n",
        "    timestamp_column=\"timestamp\",\n",
        "    window_duration=24,\n",
        "    window_unit=\"hours\"\n",
        ")\n",
        "\n",
        "# 2) Average transactionAmount over 48h\n",
        "transactions.feature_engineering.create_aggregate_features(\n",
        "    column_to_operate=\"transactionAmount\",\n",
        "    column_to_group=\"accountID\",\n",
        "    operation=\"AVG\",\n",
        "    new_feature_name=\"my_avg_feat_48h\",\n",
        "    timestamp_column=\"timestamp\",\n",
        "    window_duration=48,\n",
        "    window_unit=\"hours\"\n",
        ")\n",
        "\n",
        "# 3) Count transactions in the last 7 days\n",
        "transactions.feature_engineering.create_aggregate_features(\n",
        "    column_to_operate=\"transactionAmount\",\n",
        "    column_to_group=\"accountID\",\n",
        "    operation=\"COUNT\",\n",
        "    new_feature_name=\"my_count_feat_7d\",\n",
        "    timestamp_column=\"timestamp\",\n",
        "    window_duration=7,\n",
        "    window_unit=\"days\"\n",
        ")\n",
        "\n",
        "# 4) Max transaction in the last 7 days\n",
        "transactions.feature_engineering.create_aggregate_features(\n",
        "    column_to_operate=\"transactionAmount\",\n",
        "    column_to_group=\"accountID\",\n",
        "    operation=\"MAX\",\n",
        "    new_feature_name=\"my_max_feat_7d\",\n",
        "    timestamp_column=\"timestamp\",\n",
        "    window_duration=7,\n",
        "    window_unit=\"days\"\n",
        ")\n",
        "\n",
        "# Now materialize\n",
        "features_to_materialize = [\n",
        "    \"my_sum_feat_24h\", \"my_avg_feat_48h\", \"my_count_feat_7d\", \"my_max_feat_7d\"\n",
        "]\n",
        "transactions.feature_engineering.materialize_features(features_to_materialize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLTjzfLdcJmc"
      },
      "source": [
        "## 4. Constructing Prompt Templates\n",
        "We often build **prompt templates** that reference real-time or near real-time features. For instance, if we want an LLM to determine the *likelihood of fraud*, we might include the user’s `accountID`, `transactionAmount`, plus any aggregated features like `my_sum_feat_24h`.\n",
        "\n",
        "Below we define a helper class `TurboMLPromptTemplate`. In its `get_prompts` method, it calls the TurboML SDK to fetch the relevant features for each row, then formats a prompt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "f-5_vpW-P34r"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from turboml.common.feature_engineering import retrieve_features\n",
        "\n",
        "class TurboMLPromptTemplate:\n",
        "    def __init__(self, template: str, dataset_id: str):\n",
        "        self.dataset_id = dataset_id\n",
        "        self.template = template\n",
        "\n",
        "    def get_prompts(self, df: pd.DataFrame) -> List[str]:\n",
        "        # This calls TurboML's retrieve_features to get real-time features\n",
        "        prompt_data_list = retrieve_features(self.dataset_id, df).to_dict('records')\n",
        "\n",
        "        prompts = []\n",
        "        for prompt_data in prompt_data_list:\n",
        "            # We do a standard python .format(**dict) replacement\n",
        "            prompt = self.template.format(**prompt_data)\n",
        "            prompts.append(prompt)\n",
        "        return prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsuQ0J43cUsL"
      },
      "source": [
        "### Example Prompt Construction\n",
        "Now we define our prompt with placeholders for `accountID`, `transactionAmount`, and `timestamp`. We can also incorporate our newly created feature `my_sum_feat` if we want to pass that aggregated info to the LLM.\n",
        "\n",
        "**Example**: `Give the likelihood of fraud for account {accountID} for the transaction of amount {transactionAmount} performed at time {timestamp}. The sum of this account’s transactions in the past 24hr is {my_sum_feat}.`\n",
        "\n",
        "Feel free to adjust the prompt to suit your scenario (sentiment analysis, dynamic recommendations, etc.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OANbRtYIkJxG"
      },
      "source": [
        "### 4.1 Example Prompt\n",
        "Our first prompt references one feature (`my_sum_feat_24h`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "U2GOk2UWP4bh"
      },
      "outputs": [],
      "source": [
        "template_str = (\n",
        "    \"Give the likelihood of fraud for account {accountID} \"\n",
        "    \"for the transaction of amount {transactionAmount} performed at time {timestamp}. \"\n",
        "    \"The sum of this account’s transactions in the past 24h is {my_sum_feat_24h}.\"\n",
        ")\n",
        "\n",
        "fraud_prompt = TurboMLPromptTemplate(\n",
        "    template=template_str,\n",
        "    dataset_id=\"transactions_prompt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOPh3IrRkVm6"
      },
      "source": [
        "### 4.2 Example Prompt\n",
        "Here we reference **multiple** features: `my_sum_feat_24h`, `my_avg_feat_48h`, `my_count_feat_7d`, and `my_max_feat_7d`. This might be used for a more detailed risk analysis prompt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cEOatIp6kY2M"
      },
      "outputs": [],
      "source": [
        "template_str_2 = (\n",
        "    \"Based on the following data for account {accountID}:\\n\"\n",
        "    \"- sum of last 24 hours: {my_sum_feat_24h}\\n\"\n",
        "    \"- average transaction in last 48 hours: {my_avg_feat_48h}\\n\"\n",
        "    \"- total transactions in last 7 days: {my_count_feat_7d}\\n\"\n",
        "    \"- max transaction in last 7 days: {my_max_feat_7d}\\n\"\n",
        "    \"Please determine the risk rating for this transaction of {transactionAmount} at time {timestamp}.\"\n",
        ")\n",
        "\n",
        "risk_prompt = TurboMLPromptTemplate(\n",
        "    template=template_str_2,\n",
        "    dataset_id=\"transactions_prompt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAEWTZWykcfh"
      },
      "source": [
        "## 5. Testing the Prompts\n",
        "We'll retrieve the **last 5** records from our local DataFrame, call `get_prompts(...)`, and see how they look. Notice that in a production system, each query might come from a live user or from an API endpoint, which would retrieve real-time features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kuFOgfdKkcSi"
      },
      "outputs": [],
      "source": [
        "sample_df = transactions.preview_df[-5:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skQo7h5-mxR7",
        "outputId": "21bb4777-1869-4b23-acbd-3c1d036ec5de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Prompt #1 (Fraud prompt) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:turboml.common.internal:Starting to upload data... Total rows: 5\n",
            "Progress: 100%|██████████| 1.00/1.00 [00:00<00:00, 1.10kchunk/s]\n",
            "INFO:turboml.common.internal:Completed data upload.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prompt 1:\n",
            "Give the likelihood of fraud for account A844428178170104 for the transaction of amount 145.59 performed at time 1380585391.0. The sum of this account’s transactions in the past 24h is 145.59.\n",
            "\n",
            "\n",
            "Prompt 2:\n",
            "Give the likelihood of fraud for account A844428178164561 for the transaction of amount 84.79 performed at time 1380585437.0. The sum of this account’s transactions in the past 24h is 84.79.\n",
            "\n",
            "\n",
            "Prompt 3:\n",
            "Give the likelihood of fraud for account A844427182177392 for the transaction of amount 49.99 performed at time 1380585481.0. The sum of this account’s transactions in the past 24h is 49.99.\n",
            "\n",
            "\n",
            "Prompt 4:\n",
            "Give the likelihood of fraud for account A844427572488296 for the transaction of amount 148.74 performed at time 1380585504.0. The sum of this account’s transactions in the past 24h is 148.74.\n",
            "\n",
            "\n",
            "Prompt 5:\n",
            "Give the likelihood of fraud for account A985156974500548 for the transaction of amount 148.39 performed at time 1380585550.0. The sum of this account’s transactions in the past 24h is 148.39.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Prompt #1 (Fraud prompt) ---\")\n",
        "prompts_fraud = fraud_prompt.get_prompts(df=sample_df)\n",
        "for i, prompt in enumerate(prompts_fraud):\n",
        "    print(f\"\\nPrompt {i+1}:\\n{prompt}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CuQUQjRm3H6",
        "outputId": "78e681eb-9531-435a-a428-325fd22cd285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Prompt #2 (Risk prompt) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:turboml.common.internal:Starting to upload data... Total rows: 5\n",
            "Progress: 100%|██████████| 1.00/1.00 [00:00<00:00, 982chunk/s]\n",
            "INFO:turboml.common.internal:Completed data upload.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prompt 1:\n",
            "Based on the following data for account A844428178170104:\n",
            "- sum of last 24 hours: 145.59\n",
            "- average transaction in last 48 hours: 145.58999633789062\n",
            "- total transactions in last 7 days: 1\n",
            "- max transaction in last 7 days: 145.59\n",
            "Please determine the risk rating for this transaction of 145.59 at time 1380585391.0.\n",
            "\n",
            "\n",
            "Prompt 2:\n",
            "Based on the following data for account A844428178164561:\n",
            "- sum of last 24 hours: 84.79\n",
            "- average transaction in last 48 hours: 84.79000091552734\n",
            "- total transactions in last 7 days: 1\n",
            "- max transaction in last 7 days: 84.79\n",
            "Please determine the risk rating for this transaction of 84.79 at time 1380585437.0.\n",
            "\n",
            "\n",
            "Prompt 3:\n",
            "Based on the following data for account A844427182177392:\n",
            "- sum of last 24 hours: 49.99\n",
            "- average transaction in last 48 hours: 49.9900016784668\n",
            "- total transactions in last 7 days: 1\n",
            "- max transaction in last 7 days: 49.99\n",
            "Please determine the risk rating for this transaction of 49.99 at time 1380585481.0.\n",
            "\n",
            "\n",
            "Prompt 4:\n",
            "Based on the following data for account A844427572488296:\n",
            "- sum of last 24 hours: 148.74\n",
            "- average transaction in last 48 hours: 148.74000549316406\n",
            "- total transactions in last 7 days: 1\n",
            "- max transaction in last 7 days: 148.74\n",
            "Please determine the risk rating for this transaction of 148.74 at time 1380585504.0.\n",
            "\n",
            "\n",
            "Prompt 5:\n",
            "Based on the following data for account A985156974500548:\n",
            "- sum of last 24 hours: 148.39\n",
            "- average transaction in last 48 hours: 148.38999938964844\n",
            "- total transactions in last 7 days: 1\n",
            "- max transaction in last 7 days: 148.39\n",
            "Please determine the risk rating for this transaction of 148.39 at time 1380585550.0.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Prompt #2 (Risk prompt) ---\")\n",
        "prompts_risk = risk_prompt.get_prompts(df=sample_df)\n",
        "for i, prompt in enumerate(prompts_risk):\n",
        "    print(f\"\\nPrompt {i+1}:\\n{prompt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFbpTsWFnQ30"
      },
      "source": [
        "## 6. (Optional) LLM Inference\n",
        "We can now pass these prompts to an LLM endpoint (like OpenAI, Anthropic, Gemini or a local model) to get responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLzCwK8Hnqel"
      },
      "outputs": [],
      "source": [
        "# !%pip install --upgrade openai\n",
        "# from openai import OpenAI\n",
        "\n",
        "# ## Set the API key and model name\n",
        "# MODEL=\"gpt-4o\"\n",
        "# client = OpenAI(api_key=\"YOUR_API_KEY\")  # Replace with your API key\n",
        "\n",
        "# # Make the API call using the first prompt from your prompts_fraud list\n",
        "# completion = client.chat.completions.create(\n",
        "#     model=MODEL,\n",
        "#     messages=[\n",
        "#         {\n",
        "#             \"role\": \"system\", \n",
        "#             \"content\": \"You are a financial assistant. Help me assess the risk of fraud for this transaction.\"\n",
        "#         },\n",
        "#         {\n",
        "#             \"role\": \"user\", \n",
        "#             \"content\": prompts_fraud[0]\n",
        "#         }\n",
        "#     ],\n",
        "#     max_tokens=150\n",
        "# )\n",
        "# print(\"Assistant:\", completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0TRzHoqkqlY"
      },
      "source": [
        "By integrating **TurboML** with your LLM workflow:\n",
        "- You can easily **materialize** real-time data into prompts.\n",
        "- You can keep track of **complex** features without writing a lot of custom code.\n",
        "- You can create more powerful and **context-aware** LLM-based applications."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
